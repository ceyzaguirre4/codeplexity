<!doctype html>
<html lang='en'>
	<head>
		<meta charset='utf-8'>
		<title>CodePlexity</title>
		<link rel='icon' href='/~jjyu/favicon.png'>
		<link rel='stylesheet' href='project_page.css' type='text/css'>
		<meta name='viewport' content='width=device-width, initial-scale=1'>

		<style>
		  .main-container {
			display: flex;
			justify-content: center;
			max-width: 1000px;
			margin: 0px auto;
		  }

		  .center {
			display: block;
			margin-left: auto;
			margin-right: auto;
			width: 15%;
		  }
		  .video-container-rosetta {
			display: flex;
			justify-content: center; /* Align videos to the center */
			flex-wrap: nowrap; /* Prevents wrapping of items */
		  }

		  .video-wrapper-rosetta {
			flex: 0 0 20%; /* Do not grow, do not shrink, start at 32% width */
			margin: 0 0.5%; /* Provide some space between the videos */
			box-sizing: border-box; /* Include padding and borders in the element's total width and height */
		  }

		  .video-container-single {
			display: flex;
			justify-content: center; /* Align videos to the center */
			flex-wrap: wrap; /* Prevents wrapping of items */
			margin-bottom: 20px; /* Adjust this value to add vertical space between rows */
		  }

		  .video-wrapper-single {
			flex: 0 0 35%; /* Do not grow, do not shrink, start at 32% width */
			margin: 0 0.5%; /* Provide some space between the videos */
			box-sizing: border-box; /* Include padding and borders in the element's total width and height */
		  }

		  .video-title {
			text-align: center; /* Center the title text above the video */
			margin-bottom: 0.3em; /* Space between title and video */
		  }

		  video {
			width: 100%; /* Ensure the video fills its container */
			height: auto;
			display: block; /* Ensures that the video is a block-level element */
		  }

		   /* Style the button that is used to open and close the collapsible content */
			.collapsible {
			background-color: rgb(214, 214, 242);
			color: #444;
			cursor: pointer;
			padding: 18px;
			width: 100%;
			border: none;
			text-align: left;
			outline: none;
			font-size: 15px;
			}

			/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
			.active, .collapsible:hover {
			background-color: rgb(126, 177, 219);
			}

			/* Style the collapsible content. Note: hidden by default */
			.collapsible-content {
			padding: 0 18px;
			display: none;
			overflow: hidden;
			background-color: #f1f1f1;
			}
    </style>

	</head>

	<body>
		<h1 class='project_title'>Understanding Complexity in VideoQA via Visual Program Generation</h1>
		<div class='project_date'>May 9th, 2025</div>

		<h2 class='project_section'>Authors</h2>
		<div class='project_author_wrapper'>
			<a class='project_author' href='https://ceyzaguirre4.github.io'>
				<img class='author_icon' src='https://avatars3.githubusercontent.com/u/20346844?s=460&v=4'>
				<p>Cristobal Eyzaguirre</p>
			</a>
			<a class='project_author' href='https://pvtokmakov.github.io/home/'>
				<img class='author_icon' src='img/pavel.jpeg'>
				<p>Pavel Tokmakov</p>
			</a>
		</div>

		<h2 class='project_section'>Abstract</h2>
		We propose a data-driven approach to analyzing query complexity in Video Question Answering (VideoQA).
		Previous efforts in benchmark design have relied on human expertise to design challenging questions, yet we experimentally show that humans struggle to predict which questions are difficult for machine learning models.
		Our automatic approach leverages recent advances in code generation for visual question answering, using the complexity of generated code as a proxy for question difficulty.
		We demonstrate that this measure correlates significantly better with model performance than human estimates.
		To operationalize this insight, we propose an algorithm for estimating question complexity from code. It identifies fine-grained primitives that correlate with the hardest questions for any given set of models, making it easy to scale to new approaches in the future.
		Finally, to further illustrate the utility of our method, we extend it to automatically generate complex questions, constructing a new benchmark that is 1.9 times harder than the popular NExT-QA.



		<h2 class='project_section'>Material</h2>
		<div class='project_material_wrapper'>
			<a style='margin-left:27.3%;' class='project_material' href='https://arxiv.org/abs/2206.02846'>
				<img style='margin: 4.1% 0;' class='shadow_icon' src='img/paper.png'>
				<p>Paper</p>
			</a>
			<a class='project_material' href='https://github.com/ceyzaguirre4/codeplexity'>
				<img style='margin: 14.6% 0;' src='icons/github.svg'>
				<p>Code</p>
			</a>
		</div>
	</body>
</html>
